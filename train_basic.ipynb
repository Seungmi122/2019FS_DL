{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import cm as c\n",
    "\n",
    "from utils.val import *\n",
    "from engine.train import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define/Import your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### edit this part ######################\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
    "                                  input_shape=(None, None,3)))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvMax(filters, size, apply_batchnorm=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(\n",
    "      keras.layers.Conv2D(filters, size, padding='same\n",
    "                             ,kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(keras.layers.ReLU())\n",
    "    result.add(keras.layers.MaxPool2D())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv(filters, size, apply_batchnorm=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(\n",
    "      keras.layers.Conv2D(filters, size, padding='same'\n",
    "                             ,kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCNN():\n",
    "    inputs = tf.keras.layers.Input(shape=[None,None,3])\n",
    "\n",
    "    mod1 = [\n",
    "    ConvMax(16, 9, apply_batchnorm=False),\n",
    "    ConvMax(32, 7),\n",
    "    ConvMax(16, 7),\n",
    "    Conv(8, 7),\n",
    "    ]\n",
    "\n",
    "    mod2 = [\n",
    "    ConvMax(20, 7, apply_batchnorm=False),\n",
    "    ConvMax(40, 5),\n",
    "    ConvMax(20, 5),\n",
    "    Conv(10, 5),\n",
    "    ]\n",
    "    \n",
    "    mod3 = [\n",
    "    ConvMax(24, 5, apply_batchnorm=False),\n",
    "    ConvMax(48, 3),\n",
    "    ConvMax(24, 3),\n",
    "    Conv(12, 3),\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    x = inputs\n",
    "\n",
    "    for val1, val2, val3 in zip(mod1, mod2, mod3):\n",
    "        x1 = val1(x)\n",
    "        x2 = val2(x)\n",
    "        x3 = val3(x)\n",
    "        x = keras.layers.Concatenate()([x1,x2,x3])\n",
    "\n",
    "    density_map = keras.layers.Conv2D(1, 1, padding='same', activation='linear')\n",
    "\n",
    "    x = density_map(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_125 (Sequential)     (None, None, None, 1 3904        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_129 (Sequential)     (None, None, None, 2 2960        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_133 (Sequential)     (None, None, None, 2 1824        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, None, None, 6 0           sequential_125[0][0]             \n",
      "                                                                 sequential_129[0][0]             \n",
      "                                                                 sequential_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_126 (Sequential)     (None, None, None, 3 94112       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_130 (Sequential)     (None, None, None, 4 60040       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_134 (Sequential)     (None, None, None, 4 25968       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, None, None, 1 0           sequential_126[0][0]             \n",
      "                                                                 sequential_130[0][0]             \n",
      "                                                                 sequential_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_127 (Sequential)     (None, None, None, 1 94096       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_131 (Sequential)     (None, None, None, 2 60020       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_135 (Sequential)     (None, None, None, 2 25944       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, None, None, 6 0           sequential_127[0][0]             \n",
      "                                                                 sequential_131[0][0]             \n",
      "                                                                 sequential_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_128 (Sequential)     (None, None, None, 8 23528       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_132 (Sequential)     (None, None, None, 1 15010       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_136 (Sequential)     (None, None, None, 1 6492        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, None, None, 3 0           sequential_128[0][0]             \n",
      "                                                                 sequential_132[0][0]             \n",
      "                                                                 sequential_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 31          concatenate_23[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 413,929\n",
      "Trainable params: 413,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MCNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 1 loss = 73376080.00000000 Test MAE =  713.1232\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# define epochs and learning rates \n",
    "#############edit this if you want to change epochs or lr###############\n",
    "fit(model, epochs=1, learning_rate = 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize test outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############change test_input to check how your model works with a test data#######\n",
    "generate_images(model, test_input = 'ShanghaiTech/part_A/test_data/images/IMG_100.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
