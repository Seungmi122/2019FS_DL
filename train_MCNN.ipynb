{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import cm as c\n",
    "\n",
    "from utils.val import *\n",
    "from engine.train import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvMax(filters, size, max_pooling = False, apply_batchnorm=False):\n",
    "    '''\n",
    "    objective: create a model with Conv2D, Relu and Maxpool2D layers\n",
    "    param: filters - int \n",
    "           size - int for kernel size\n",
    "           max_pooing - boolean for whether to include maxpool layer or not\n",
    "    '''\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(\n",
    "        keras.layers.Conv2D(filters, size, padding='same' ,kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    result.add(keras.layers.ReLU())\n",
    "    if max_pooling:\n",
    "        result.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCNN():\n",
    "    inputs = tf.keras.layers.Input(shape=[None,None,3])\n",
    "\n",
    "    mod1 = [\n",
    "    ConvMax(16, 9, max_pooling = True, apply_batchnorm=False),\n",
    "    ConvMax(32, 7, max_pooling = True),\n",
    "    ConvMax(16, 7, max_pooling = True),\n",
    "    ConvMax(8, 7),\n",
    "    ]\n",
    "\n",
    "    mod2 = [\n",
    "    ConvMax(20, 7, max_pooling = True, apply_batchnorm=False),\n",
    "    ConvMax(40, 5, max_pooling = True),\n",
    "    ConvMax(20, 5, max_pooling = True),\n",
    "    ConvMax(10, 5),\n",
    "    ]\n",
    "    \n",
    "    mod3 = [\n",
    "    ConvMax(24, 5, max_pooling = True, apply_batchnorm=False),\n",
    "    ConvMax(48, 3, max_pooling = True),\n",
    "    ConvMax(24, 3, max_pooling = True),\n",
    "    ConvMax(12, 3),\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    x = inputs\n",
    "\n",
    "    for val1, val2, val3 in zip(mod1, mod2, mod3):\n",
    "        x1 = val1(x)\n",
    "        x2 = val2(x)\n",
    "        x3 = val3(x)\n",
    "        x = keras.layers.Concatenate()([x1,x2,x3])\n",
    "\n",
    "    density_map = keras.layers.Conv2D(1, 1, padding='same', activation='linear')\n",
    "\n",
    "    x = density_map(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, None, 1 3888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, None, None, 2 2940        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, None, None, 2 1800        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 6 0           sequential[0][0]                 \n",
      "                                                                 sequential_4[0][0]               \n",
      "                                                                 sequential_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, None, 3 94080       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, None, None, 4 60000       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, None, None, 4 25920       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 1 0           sequential_1[0][0]               \n",
      "                                                                 sequential_5[0][0]               \n",
      "                                                                 sequential_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, None, None, 1 94080       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, None, None, 2 60000       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, None, None, 2 25920       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 6 0           sequential_2[0][0]               \n",
      "                                                                 sequential_6[0][0]               \n",
      "                                                                 sequential_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, None, None, 8 23520       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, None, None, 1 15000       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, None, None, 1 6480        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           sequential_3[0][0]               \n",
      "                                                                 sequential_7[0][0]               \n",
      "                                                                 sequential_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 1 31          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 413,659\n",
      "Trainable params: 413,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Learning started. It takes sometime.\n",
      "Epoch: 1 loss = 19034748.00000000 Test MAE =  710.3464\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# define epochs and learning rates \n",
    "#############edit this if you want to change epochs or lr###############\n",
    "fit(model, epochs=1, learning_rate = 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize test outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############change test_input to check how your model works with a test data#######\n",
    "generate_images(model, test_input = 'ShanghaiTech/part_A/test_data/images/IMG_100.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
