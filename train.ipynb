{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from PIL import Image\n",
    "from image import *\n",
    "import tensorflow.image\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D \n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import dataset\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "with open('train_data_list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        inner_list = [elt.strip() for elt in line.split(',')]\n",
    "        train_list.append(inner_list)\n",
    "train_list = [val.replace('\\'','') for val in train_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "with open('test_data_list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        inner_list = [elt.strip() for elt in line.split(',')]\n",
    "        test_list.append(inner_list)\n",
    "test_list = [val.replace('\\'','') for val in test_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image\n",
    "def load_data(paths, train = True):\n",
    "    for img_path in paths:\n",
    "        gt_path = img_path.decode(\"utf-8\").replace('.jpg','.h5').replace('images','ground-truth')\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels = 3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "        gt_file = h5py.File(gt_path, 'r')\n",
    "        target = np.asarray(gt_file['density'])\n",
    "\n",
    "        target = cv2.resize(target,(int(target.shape[1]/8),int(target.shape[0]/8)),interpolation = cv2.INTER_CUBIC)*64\n",
    "\n",
    "    \n",
    "        yield (img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "                        load_data, args = [train_list] , output_types = (tf.float32, tf.float32), output_shapes = ((None,None,3), (None,None)))\n",
    "train_dataset = train_dataset.shuffle(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "                   load_data, args = [test_list] , output_types = (tf.float32, tf.float32), output_shapes = ((None,None,3), (None,None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 255\n",
    "IMG_WIDTH = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, input_image, gt_image):\n",
    "\n",
    "    output = model(input_image)\n",
    "    pred = np.sum(output) \n",
    "    \n",
    "    ground_truth = tf.cast(ground_truth, tf.float32)\n",
    "    ground_truth = np.sum(ground_truth)\n",
    "    \n",
    "    # mean squared error\n",
    "    loss = loss_object(ground_truth, pred)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.28235295 0.32941177 0.28235295]\n",
      "  [0.2392157  0.28627452 0.2392157 ]\n",
      "  [0.20784315 0.25490198 0.21568629]\n",
      "  ...\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69411767 0.8117648  0.8431373 ]]\n",
      "\n",
      " [[0.23529413 0.28235295 0.23529413]\n",
      "  [0.20392159 0.2509804  0.20392159]\n",
      "  [0.1764706  0.22352943 0.18431373]\n",
      "  ...\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69411767 0.8117648  0.8431373 ]]\n",
      "\n",
      " [[0.20000002 0.24705884 0.20784315]\n",
      "  [0.17254902 0.21960786 0.18039216]\n",
      "  [0.14509805 0.19215688 0.15294118]\n",
      "  ...\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69803923 0.81568635 0.8470589 ]\n",
      "  [0.69411767 0.8117648  0.8431373 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.49411768 0.5764706  0.5803922 ]\n",
      "  [0.50980395 0.5921569  0.59607846]\n",
      "  [0.52156866 0.6039216  0.60784316]\n",
      "  ...\n",
      "  [0.3803922  0.4431373  0.4431373 ]\n",
      "  [0.38431376 0.44705886 0.44705886]\n",
      "  [0.38431376 0.44705886 0.44705886]]\n",
      "\n",
      " [[0.50980395 0.5921569  0.59607846]\n",
      "  [0.5137255  0.59607846 0.6       ]\n",
      "  [0.52156866 0.6039216  0.60784316]\n",
      "  ...\n",
      "  [0.37254903 0.43529415 0.43529415]\n",
      "  [0.38823533 0.45098042 0.45098042]\n",
      "  [0.3921569  0.454902   0.454902  ]]\n",
      "\n",
      " [[0.5294118  0.6117647  0.6156863 ]\n",
      "  [0.5294118  0.6117647  0.6156863 ]\n",
      "  [0.5294118  0.6117647  0.6156863 ]\n",
      "  ...\n",
      "  [0.36078432 0.42352945 0.42352945]\n",
      "  [0.38431376 0.44705886 0.44705886]\n",
      "  [0.40000004 0.46274513 0.46274513]]], shape=(768, 1024, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# check how it shows\n",
    "for img, tar in train_dataset.take(1):\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
    "                                  input_shape=(None, None,3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungmi/anaconda3/envs/pyDL/lib/python3.6/site-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-823.663\n",
      "1018630.0\n",
      "576.0004\n"
     ]
    }
   ],
   "source": [
    "for img, target in train_dataset.take(1):\n",
    "        output = model(np.expand_dims(img,0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        grads = grad(model, images, labels)                \n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_loss = avg_loss + loss\n",
    "        avg_train_acc = avg_train_acc + acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_dataset:        \n",
    "        acc = evaluate(model, images, labels)        \n",
    "        avg_test_acc = avg_test_acc + acc\n",
    "        test_step += 1    \n",
    "    avg_test_acc = avg_test_acc / test_step    \n",
    "\n",
    "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
    "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
    "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
    "    \n",
    "print('Learning Finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
